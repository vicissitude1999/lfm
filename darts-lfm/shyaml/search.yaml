apiVersion: batch/v1
kind: Job
metadata:
  name: {}
spec:
  template:
#    metadata:
#      labels:
#        k8s-app: research
    spec:
      containers:
      - name: pytorch-container
        image: gitlab-registry.nrp-nautilus.io/prp/jupyter-stack/prp:latest
        workingDir: /renyi-volume/lfm/darts-lfm/shyaml
        command: ["bash", "search-{}.sh"]
        resources:
          requests:
            memory: "4Gi"
            cpu: "4"
            nvidia.com/gpu: 1
          limits:
            memory: "4Gi"
            cpu: "4"
            nvidia.com/gpu: 1
        volumeMounts:
        - name: renyi-volume
          mountPath: /renyi-volume

      restartPolicy: Never

      volumes:
        - name: renyi-volume
          persistentVolumeClaim:
            claimName: renyi-volume

      affinity:
         nodeAffinity:
           requiredDuringSchedulingIgnoredDuringExecution:
             nodeSelectorTerms:
             - matchExpressions:
               - key: gpu-type
                 operator: In
                 values:
                   - 1080Ti
               - key: topology.kubernetes.io/region
                 operator: In
                 values:
                   - us-west
  backoffLimit: 1